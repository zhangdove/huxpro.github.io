---
layout:     post
title:      "hadoop 2.6.5安装详细步骤"	
subtitle:   "apache hadoop"			
date:       2017-04-15 15:39:00
author:     "dove"
header-img: "img/_posts/hadoop-logo.jpg"  
header-mask: 0.3
catalog:    true
tags:
    - install
    - hadoop
---


> 集群之前使用hadoop2.6.4 + sqoop 1.99.4 出现了找不到主机路由，那套集群坏了两天，准备drop掉了，然后重装虚拟机换一套新环境，亲测安装，并顺便记录下来。

**apache hadoop2.6.5安装与配置**
# 1.安装jdk #
	卸载jdk
	查看jdk安装包: rpm -qa | grep java
	一键删除jdk: rpm -e --nodeps `rpm -qa | grep java`
	tar -xzvf jdk-7u67-linux-x64.tar.gz -C /usr/java/
	vi /etc/profile添加如下内容
	export JAVA_HOME=/usr/java/jdk1.7.0_67
	export PATH=.:$JAVA_HOME/bin:$PATH
	source /etc/profile
	查看jdk版本信息 java -version (对了，最好使用oracle版本的jdk)

# 2.安装ssh通信 #
> [ssh免密登录(CentOs7)](http://www.aboutyun.com/home.php?mod=space&uid=47062&do=blog&id=3291)
# 3.配置hadoop环境 #



- 1)官网下载 hadoop-2.6.5.tar.gz包 下载地址

> 	http://archive.apache.org/dist/hadoop/common/hadoop-2.6.5/


- 2)将hadoop解压到/usr目录下

> 	sudo tar -zxvf hadoop-2.6.5.tar.gz -C /usr  

- 3)配置环境变量
> 	sudo nano /etc/profile
> 	配置环境变量，将hadoop目录指定
> 	export HADOOP_HOME=/usr/hadoop-2.6.5
> 	export PATH=$PATH:$HADOOP_HOME/bin
> 	export PATH=$PATH:$HADOOP_HOME/sbin -- 启动集群的start-all.sh命令，将其配置到环境中(个人习惯)
> 	source /etc/profile

- 4)关闭防火墙
> 	service iptables stop
> 	service iptables status
> 	关闭防火墙的自动运行
> 	chkconfig iptables off
> 	chkconfig --list | grep iptables
> 	$>vi /etc/selinux/config
> 	SELINUX=disabled

- 5)创建数据存储目录和临时文件目录
> 	mkdir /usr/hadoop-2.6.5/dfs
> 	mkdir /usr/hadoop-2.6.5/dfs/data -- datanode必备
> 	mkdir /usr/hadoop-2.6.5/dfs/name --  namenode必备
> 	mkdir /usr/hadoop-2.6.5/tmp -- 临时文件目录
> 	*注意* 此处用su超管的时候需要给dfs及其下的文件赋权给用户，要不然会出现启动集群报权限错误
> 	"ExitCodeException exitCode=1: chmod: 更改"/usr/hadoop-2.6.5/dfs/data" 的权限: 不允许的操作"


- 6)配置yarn-env.sh 和 hadoop-env.sh

将 yarn-env.sh 和 hadoop-env.sh 配置下的jdk指定目录 ，否则报  "Error: JAVA_HOME is not set and could not be found." 
>	export JAVA_HOME=/usr/java/jdk1.7.0_67
# 7)core-site.xml配置文件 #
    <property>
    	<name>dfs.namenode.secondary.http-address</name>
    	<value>master:9001</value>
    </property>
    <!--配置secondnamenode的地址与端口，不配置则出现 "Starting secondary namenodes [0.0.0.0]"  可以通过master:9001去访问secondnamenode-->
    <property>
    	<name>fs.defaultFS</name>
    	<value>hdfs://master:8020</value> -- 访问集群目录，默认是9000
    </property>
    <property>
    	<name>hadoop.tmp.dir</name>
    	<value>/usr/hadoop-2.6.5/tmp</value> -- 此处创建目录见第五步
    </property>
    <property>
    	<name>hadoop.proxyuser.zcy.hosts</name>   -- 设置用户代理组
    	<value>*</value>
    </property>
    <property>
    	<name>hadoop.proxyuser.zcy.groups</name>-- 设置用户组代理
    	<value>*</value>
    </property>
# 8)hdfs-site.xml配置文件 #
    <property>
    	<name>dfs.replication</name> --因为只有两个节点slave1和slave2，所以副本配置为2
    	<value>2</value>
    </property>
    <property>
    	<name>dfs.namenode.name.dir</name>
    	<value>file:/usr/hadoop-2.6.5/dfs/name</value> -- namenode存储元数据信息
    </property>
    <property>
    	<name>dfs.datanode.data.dir</name>
    	<value>file:/usr/hadoop-2.6.5/dfs/data</value> -- datanode存储数据
    </property>
# 9)mapred-site.xml配置 #
    cp mapred-site.xml.template mapred-site.xml
    <property>
    	<name>mapreduce.framework.name</name> --指定是使用yarn运行mapreduce程序。
    	<value>yarn</value>
    </property>
# 10)yarn-site.xml #
    <property>
    	<name>yarn.nodemanager.aux-services</name> <!-- NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序-->
    	<value>mapreduce_shuffle</value>
    </property>
    <property>
    	<name>yarn.resourcemanager.hostname</name> <!--指定yarn的主机，要不然一直找0.0.0.0:8031 -->
    	<value>master</value>
    </property>
    <!-- 不设定 yarn.resourcemanager.hostname nodemanager的日志一直在寻找 org.apache.hadoop.yarn.client.RMProxy: Connecting to ResourceManager at /0.0.0.0:8031   -->
    <property>
    	<name>yarn.nodemanager.aux-services.mapreduce.shuffle.class</name> <!--YARN集群有多个节点必配 -->
    	<value>org.apache.hadoop.mapred.ShuffleHandler</value>
    </property>
# 11)slaves 配置(多少节点就写多少节点机器) #
    slave1
    slave2

# 12)复制到其他节点 #
    sudo scp -r /usr/hadoop-2.6.5/ slave1:/usr/
    sudo scp -r /usr/hadoop-2.6.5/ slave2:/usr/

然后在各个子节点运行 sudo chown zcy:zcy /usr/hadoop-2.6.5/ -R 更改权限
# 13)格式化namenode #

    /usr/hadoop-2.6.5/bin/hdfs namenode -format
 
# 14)启动集群完工 #

    start-all.sh


到了这里，还有一个 `"Unable to load native-hadoop library for your platform... using builtin-java classes where applicable"` 的问题，好像是要做源码编译，回家了用另一台虚拟机做编译工作。

集群安装成功，基本上能用web的50070和shell命令见环境，后续有新的配置和详解再相继添加